{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From $\\textbf{Pattern Recognition and Machine Learning, Christopher M. Bishop, Springer 2006}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that we want to maximize a function $f(x)$ with constraints $g(x) = 0$.\n",
    "\n",
    "If x is n-dimensional vector, then g(x) can be thought of (n-1)-dimensional surface, the constrained surface. \n",
    "\n",
    "We want to show that the gradient of g in any point x on the constrained surface is orthogonal to it. Take taylor expansion at x: <br>\n",
    "\n",
    "$g(x + \\epsilon) \\approx g(x) + \\epsilon^{T}\\nabla g(x)$\n",
    "\n",
    "$g(x)$ and  $g(x + \\epsilon)$ lie on the surface so $g(x) = g(x + \\epsilon) = 0$, <br>\n",
    "$\\epsilon$ is infinitesimal and is parallel to the surface. So <br>\n",
    "$\\epsilon^{T}\\nabla g(x) = 0$ and $\\nabla g(x)$ must be orthogonal to $\\epsilon$, so it is to the surface\n",
    "\n",
    "\n",
    "Now, let's come back to the problem of maximizing f(x). We know that we look for the optimal point on the constrained surface. Suppose that there is a point $x^{*}$, which satisfies us. Can we improve it? Take $\\nabla f(x^{*})$ and consider Taylor expansion \n",
    "$f(x^{*} + \\epsilon) \\approx f(x^{*}) + \\epsilon^{T}\\nabla f(x^{*})$, <br>if the gradient was not orthogonal to $\\epsilon$, it would create an acute angle (or to -$\\epsilon$), so the dot product would be positive and a new point $x^{*} + \\epsilon$ would be an improvement over $x^{*}$. \n",
    "\n",
    "Hence, at the optimal point both $\\nabla g$ and $\\nabla f$ must be linearly dependent (the same direction), which can be written as: <br>\n",
    "\n",
    "$\\nabla f + \\lambda \\nabla g = 0$ ($\\lambda$ is called Lagrance multiplier and $\\lambda \\neq 0$)\n",
    "\n",
    "Lagrangian function is defined as <br><br>\n",
    "$L(x, \\lambda) = f(x) + \\lambda g(x)$\n",
    "\n",
    "If we look for stationary points x of Lagrangian function: <br><br>\n",
    "$\\nabla_{x}L(x, \\lambda) = \\nabla f + \\lambda \\nabla g = 0$. It gives us a set of points x, in which gradients of f and g are parallel (required condition for optimality of x), but not necessariliy on the constrained surface (which requires $g(x) = 0$)<br><br>\n",
    "If we look for stationary points $\\lambda$ of Lagrangian function: <br>\n",
    "$\\frac{\\partial L(x, \\lambda)}{\\partial \\lambda} = g(x) = 0$\n",
    "\n",
    "So to maximize $f$ we look for stationary points of $L(x, \\lambda)$ with respect both to $x$ and $\\lambda$.\n",
    "\n",
    "\n",
    "Now suppose that the constraint is $g(x) \\geq 0$.\n",
    "\n",
    "If we consider a point that satisfies $g(x) \\gt 0$, then the constraint g doesn't have any influence on f and we just have to see if $\\nabla f(x) = 0$. In this case $\\lambda = 0$. If, on the other hand a point under consideration satisfies $g(x) = 0$, then in order x to satisfy the optimality conditions we have analogous situations as before. We need linear dependence between $\\nabla g(x)$ and $\\nabla f(x)$, but here we need additionally the direction of gradient of f to be opposite to the gradient of g, otherwise we could move from x to the direction outward from the surface to increase value of f. So $\\nabla f(x) = -\\lambda \\nabla g(x)$ ($\\lambda \\gt 0$). In both cases, we have: <br>\n",
    "$\\lambda g(x) = 0$\n",
    "\n",
    "The problem of maximization of f is equivalent to optimizing Lagrange function $L(x, \\lambda) = f(x) + \\lambda g(x)$ with respect to $x$ and $\\lambda$ subject to the conditions: <br><br>\n",
    "$g(x) \\ge 0$ <br>\n",
    "$\\lambda \\ge 0$ <br>\n",
    "$\\lambda g(x) = 0$ \n",
    "\n",
    "These are known as Karush-Kuhn-Tucker (KKT) conditions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
